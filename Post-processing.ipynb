{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc2e96-cd43-4af7-b0e5-fb3fa25418cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "file_path = 'gcs-bucket/Output-2/december_23.nc'\n",
    "\n",
    "ds = xr.open_dataset(file_path, decode_times=False)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5161e4-a545-4b97-996c-fe8bba96f0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds = ds.assign_coords(\n",
    "    time=pd.to_timedelta(ds.time.values, unit=\"ns\")\n",
    ")\n",
    "\n",
    "print(ds.time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116ee00-8f23-4df0-b594-89d63e06907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds[['total_precipitation_6hr']]\n",
    "\n",
    "# Display the updated dataset to verify\n",
    "print(\"Dataset after keeping only 'total_precipitation_6hr':\")\n",
    "print(ds)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68e8cba-bbfe-4543-a97c-e1f79f7f2b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "original_timesteps = ds.sizes['time']\n",
    "sum_interval = 4\n",
    "new_timesteps = original_timesteps // sum_interval\n",
    "\n",
    "summed_dataarrays = []\n",
    "\n",
    "for i in range(new_timesteps):\n",
    "    start_index = i * sum_interval\n",
    "    end_index = start_index + sum_interval\n",
    "\n",
    "    summed_interval_data = ds['total_precipitation_6hr'].isel(time=slice(start_index, end_index)).sum(dim='time')\n",
    "\n",
    "    new_time_coord = ds.time.values[start_index]\n",
    "    summed_interval_data = summed_interval_data.expand_dims(time=[new_time_coord])\n",
    "\n",
    "    summed_dataarrays.append(summed_interval_data)\n",
    "\n",
    "summed_ds = xr.concat(summed_dataarrays, dim='time')\n",
    "\n",
    "ds_summed = xr.Dataset({'total_precipitation_6hr': summed_ds})\n",
    "\n",
    "print(\"Summed Dataset Info:\")\n",
    "print(ds_summed)\n",
    "ds_summed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c170cfa-acd2-41c9-9156-0bd608bd01cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_df = ds_summed.to_dataframe()\n",
    "summed_df = summed_df.reset_index()\n",
    "\n",
    "summed_df['total_precipitation_6hr'] = summed_df['total_precipitation_6hr'] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22e6435-acd1-4b3d-8c42-2273fae111d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_file_path = 'station_coordinates.xlsx'\n",
    "df_stations = pd.read_excel(excel_file_path)\n",
    "\n",
    "print(\"Contents of the Excel file:\")\n",
    "display(df_stations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a880458-3ae8-403a-8201-a07ea2ce41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "summed_coords = summed_df[['lat', 'lon']].drop_duplicates().values\n",
    "\n",
    "closest_coords_list = []\n",
    "\n",
    "for index, station in df_stations.iterrows():\n",
    "    station_lat = station['Latitude']\n",
    "    station_lon = station['Longitude']\n",
    "\n",
    "    distances_squared = (summed_coords[:, 0] - station_lat)**2 + (summed_coords[:, 1] - station_lon)**2\n",
    "\n",
    "    closest_index = np.argmin(distances_squared)\n",
    "\n",
    "    closest_coord = summed_coords[closest_index]\n",
    "\n",
    "    closest_coords_list.append(tuple(closest_coord))\n",
    "\n",
    "closest_coords_set = set(closest_coords_list)\n",
    "\n",
    "mask = summed_df.apply(lambda row: (row['lat'], row['lon']) in closest_coords_set, axis=1)\n",
    "\n",
    "filtered_summed_df = summed_df[mask].copy()\n",
    "\n",
    "print(\"Filtered summed_df with closest coordinates:\")\n",
    "display(filtered_summed_df.head())\n",
    "\n",
    "print(f\"\\nNumber of unique coordinate pairs in filtered_summed_df: {filtered_summed_df[['lat', 'lon']].drop_duplicates().shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8d61c-e20e-4657-9431-f9826b99d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_filename = 'filtered_precipitation_by_day.xlsx'\n",
    "with pd.ExcelWriter(excel_filename) as writer:\n",
    "    df_day1 = filtered_summed_df[filtered_summed_df['time'] == pd.to_timedelta('0 days 06:00:00')]\n",
    "    if not df_day1.empty:\n",
    "        df_day1.to_excel(writer, sheet_name='1day', index=False)\n",
    "        print(\"Data for Day 1 saved to '1day' sheet.\")\n",
    "    else:\n",
    "        print(\"No data found for Day 1.\")\n",
    "\n",
    "\n",
    "    df_day2 = filtered_summed_df[filtered_summed_df['time'] == pd.to_timedelta('1 days 06:00:00')]\n",
    "    if not df_day2.empty:\n",
    "        df_day2.to_excel(writer, sheet_name='2day', index=False)\n",
    "        print(\"Data for Day 2 saved to '2day' sheet.\")\n",
    "    else:\n",
    "        print(\"No data found for Day 2.\")\n",
    "\n",
    "    df_day3 = filtered_summed_df[filtered_summed_df['time'] == pd.to_timedelta('2 days 06:00:00')]\n",
    "    if not df_day3.empty:\n",
    "        df_day3.to_excel(writer, sheet_name='3day', index=False)\n",
    "        print(\"Data for Day 3 saved to '3day' sheet.\")\n",
    "    else:\n",
    "        print(\"No data found for Day 3.\")\n",
    "\n",
    "print(f\"\\nFiltered data saved to {excel_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f0a9920-fb02-4e9a-a668-f48097a53cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file_path = 'filtered_precipitation_by_day.xlsx'\n",
    "excel_file = pd.ExcelFile(excel_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c446299c-1371-4a01-9f4e-9572e994a75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_names = excel_file.sheet_names\n",
    "modified_dfs = {}\n",
    "\n",
    "for sheet_name in sheet_names:\n",
    "    df = excel_file.parse(sheet_name)\n",
    "    modified_dfs[sheet_name] = df\n",
    "\n",
    "print(\"Sheets read into DataFrames:\")\n",
    "for name, df in modified_dfs.items():\n",
    "    print(f\"- '{name}': {df.shape} shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef5076-5c68-4bfc-9b12-aa0e70b80898",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dates = {\n",
    "    '1day': '2023/12/02',\n",
    "    '2day': '2023/12/03',\n",
    "    '3day': '2023/12/04'\n",
    "}\n",
    "\n",
    "for sheet_name, df in modified_dfs.items():\n",
    "    if 'time' in df.columns:\n",
    "        df = df.drop(columns=['time'])\n",
    "\n",
    "    start_date_str = start_dates[sheet_name]\n",
    "\n",
    "    date_list = []\n",
    "\n",
    "    for (lat, lon), group in df.groupby(['lat', 'lon']):\n",
    "        group = group.sort_values(by='batch')\n",
    "        for batch in group['batch']:\n",
    "            current_date = pd.to_datetime(start_date_str) + pd.Timedelta(days=batch)\n",
    "            formatted_date = current_date.strftime('%Y/%m/%d')\n",
    "            date_list.append(formatted_date)\n",
    "\n",
    "    original_columns_order = [col for col in df.columns if col != 'Date']\n",
    "    df = df[original_columns_order].copy()\n",
    "    df['Date'] = date_list \n",
    "\n",
    "    cols = ['Date'] + [col for col in df.columns if col != 'Date']\n",
    "    df = df[cols]\n",
    "\n",
    "    modified_dfs[sheet_name] = df\n",
    "\n",
    "print(\"DataFrames modified with 'Date' column:\")\n",
    "for name, df in modified_dfs.items():\n",
    "    print(f\"- '{name}': {df.shape} shape, columns: {df.columns.tolist()}\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8442c9-3896-450e-a332-7fde29dd6af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_filename = 'december_23.xlsx'\n",
    "with pd.ExcelWriter(excel_filename) as writer:\n",
    "    for sheet_name, df in modified_dfs.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"Updated Excel file saved to {excel_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6686ca15-f2ec-444d-b1c6-e156022ec747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "folder = \"/home/monad/pp-2\"\n",
    "\n",
    "# Find all Excel files\n",
    "files = sorted(glob.glob(os.path.join(folder, \"*.xlsx\")))\n",
    "\n",
    "merged = {\"1day\": [], \"2day\": [], \"3day\": []}\n",
    "\n",
    "for f in files:\n",
    "    for sheet in merged.keys():\n",
    "        df = pd.read_excel(f, sheet_name=sheet)\n",
    "        merged[sheet].append(df)\n",
    "\n",
    "df_1day_all = pd.concat(merged[\"1day\"]).sort_values(\"Date\").reset_index(drop=True)\n",
    "df_2day_all = pd.concat(merged[\"2day\"]).sort_values(\"Date\").reset_index(drop=True)\n",
    "df_3day_all = pd.concat(merged[\"3day\"]).sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "output_file = os.path.join(folder, \"merged_forecasts.xlsx\")\n",
    "with pd.ExcelWriter(output_file) as writer:\n",
    "    df_1day_all.to_excel(writer, sheet_name=\"1day\", index=False)\n",
    "    df_2day_all.to_excel(writer, sheet_name=\"2day\", index=False)\n",
    "    df_3day_all.to_excel(writer, sheet_name=\"3day\", index=False)\n",
    "\n",
    "print(f\"Merged file saved at: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bbcb16-aadc-4448-80d1-29f82a26a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics_robust(df):\n",
    "    records = []\n",
    "    for station, g in df.groupby(\"Station\", sort=False):\n",
    "        valid = g[[\"total_precipitation_6hr\", \"BMD_Observed\"]].dropna()\n",
    "        n = len(valid)\n",
    "        if n == 0:\n",
    "            records.append({\"Station\": station, \"N\": 0, \"CC\": np.nan, \"ME\": np.nan, \"RMSE\": np.nan, \"POD\": np.nan})\n",
    "            continue\n",
    "\n",
    "        F = valid[\"total_precipitation_6hr\"].to_numpy()\n",
    "        O = valid[\"BMD_Observed\"].to_numpy()\n",
    "\n",
    "        if n >= 2 and np.std(F) > 0 and np.std(O) > 0:\n",
    "            CC = np.corrcoef(F, O)[0, 1]\n",
    "        else:\n",
    "            CC = np.nan\n",
    "\n",
    "        diff = F - O\n",
    "        ME = float(np.mean(diff))\n",
    "        RMSE = float(np.sqrt(np.mean(diff**2)))\n",
    "\n",
    "        hits = int(np.sum((F > 0) & (O > 0)))\n",
    "        misses = int(np.sum((F <= 0) & (O > 0)))\n",
    "        POD = hits / (hits + misses) if (hits + misses) > 0 else np.nan\n",
    "\n",
    "        records.append({\"Station\": station, \"N\": n, \"CC\": CC, \"ME\": ME, \"RMSE\": RMSE, \"POD\": POD})\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "file_path = \"merged_forecasts_with_observed_rainfall_dateonly_formatted.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "outputs = {}\n",
    "for sheet in xls.sheet_names:\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "    for col in [\"total_precipitation_6hr\", \"BMD_Observed\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    outputs[sheet] = compute_metrics_robust(df)\n",
    "\n",
    "with pd.ExcelWriter(\"graphcast_station_metrics_robust.xlsx\") as w:\n",
    "    for sheet, out in outputs.items():\n",
    "        out.to_excel(w, sheet_name=sheet, index=False)\n",
    "print(\"Saved -> graphcast_station_metrics_robust.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ef2d4-91d9-4465-8e6f-2c40619c37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics_robust(df):\n",
    "    records = []\n",
    "    for station, g in df.groupby(\"Station\", sort=False):\n",
    "        valid = g[[\"ECMWF\", \"BMD_Observed\"]].dropna()\n",
    "        n = len(valid)\n",
    "        if n == 0:\n",
    "            records.append({\"Station\": station, \"N\": 0, \"CC\": np.nan, \"ME\": np.nan, \"RMSE\": np.nan, \"POD\": np.nan})\n",
    "            continue\n",
    "\n",
    "        F = valid[\"ECMWF\"].to_numpy()\n",
    "        O = valid[\"BMD_Observed\"].to_numpy()\n",
    "\n",
    "        if n >= 2 and np.std(F) > 0 and np.std(O) > 0:\n",
    "            CC = np.corrcoef(F, O)[0, 1]\n",
    "        else:\n",
    "            CC = np.nan\n",
    "\n",
    "        diff = F - O\n",
    "        ME = float(np.mean(diff))\n",
    "        RMSE = float(np.sqrt(np.mean(diff**2)))\n",
    "\n",
    "        hits = int(np.sum((F > 0) & (O > 0)))\n",
    "        misses = int(np.sum((F <= 0) & (O > 0)))\n",
    "        POD = hits / (hits + misses) if (hits + misses) > 0 else np.nan\n",
    "\n",
    "        records.append({\"Station\": station, \"N\": n, \"CC\": CC, \"ME\": ME, \"RMSE\": RMSE, \"POD\": POD})\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "file_path = \"bmd_ecmwf_comparison.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "outputs = {}\n",
    "for sheet in xls.sheet_names:\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "    for col in [\"ECMWF\", \"BMD_Observed\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    outputs[sheet] = compute_metrics_robust(df)\n",
    "\n",
    "with pd.ExcelWriter(\"ecmwf_station_metrics_robust.xlsx\") as w:\n",
    "    for sheet, out in outputs.items():\n",
    "        out.to_excel(w, sheet_name=sheet, index=False)\n",
    "print(\"Saved -> ecmwf_station_metrics_robust.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca6914-dfe3-4c31-a780-576689e81fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics_robust(df):\n",
    "    records = []\n",
    "    for station, g in df.groupby(\"Station\", sort=False):\n",
    "        valid = g[[\"ncep\", \"BMD_Observed\"]].dropna()\n",
    "        n = len(valid)\n",
    "        if n == 0:\n",
    "            records.append({\"Station\": station, \"N\": 0, \"CC\": np.nan, \"ME\": np.nan, \"RMSE\": np.nan, \"POD\": np.nan})\n",
    "            continue\n",
    "\n",
    "        F = valid[\"ncep\"].to_numpy()\n",
    "        O = valid[\"BMD_Observed\"].to_numpy()\n",
    "\n",
    "        if n >= 2 and np.std(F) > 0 and np.std(O) > 0:\n",
    "            CC = np.corrcoef(F, O)[0, 1]\n",
    "        else:\n",
    "            CC = np.nan\n",
    "\n",
    "        diff = F - O\n",
    "        ME = float(np.mean(diff))\n",
    "        RMSE = float(np.sqrt(np.mean(diff**2)))\n",
    "\n",
    "        hits = int(np.sum((F > 0) & (O > 0)))\n",
    "        misses = int(np.sum((F <= 0) & (O > 0)))\n",
    "        POD = hits / (hits + misses) if (hits + misses) > 0 else np.nan\n",
    "\n",
    "        records.append({\"Station\": station, \"N\": n, \"CC\": CC, \"ME\": ME, \"RMSE\": RMSE, \"POD\": POD})\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "file_path = \"bmd_ncep_comparison.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "outputs = {}\n",
    "for sheet in xls.sheet_names:\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "    for col in [\"ncep\", \"BMD_Observed\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    outputs[sheet] = compute_metrics_robust(df)\n",
    "\n",
    "with pd.ExcelWriter(\"ncep_station_metrics_robust.xlsx\") as w:\n",
    "    for sheet, out in outputs.items():\n",
    "        out.to_excel(w, sheet_name=sheet, index=False)\n",
    "print(\"Saved -> ncep_station_metrics_robust.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
